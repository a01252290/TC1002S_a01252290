{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tres distribuciones con datos aleatorios\n",
    "MAXN=40 # Valor máximo para los datos\n",
    "X = np.concatenate([1.25*np.random.randn(MAXN,2), 5+1.5*np.random.randn(MAXN,2)]) \n",
    "X = np.concatenate([X,[8,3]+1.2*np.random.randn(MAXN,2)])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear etiquetas para 3 distribuciones con fines de visualización\n",
    "y = np.concatenate([np.ones((MAXN,1)),2*np.ones((MAXN,1))])\n",
    "y = np.concatenate([y,3*np.ones((MAXN,1))])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='b')\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='g')\n",
    "plt.title('Datos generados')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((10,4))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X[:,0],X[:,1],color='r')\n",
    "plt.title('Datos vistos por el algoritmo')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "K=3 # Asumiendo que existen 3 clusters\n",
    "\n",
    "clf = cluster.KMeans(init='random', n_clusters=K)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las clases de los datos de entrenamiento\n",
    "print (clf.labels_)    # usando el atributo labels_\n",
    "print (clf.predict(X)) # equivalente, con el método predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X[(y==1).ravel(),0]) #numpy.ravel() regresa un arreglo plano\n",
    "print (X[(y==1).ravel(),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='b')\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='g')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan nuevos datos para probar el predictor\n",
    "x = np.linspace(-5,15,200) # genera 200 números en el intervalo -5..15\n",
    "XX,YY = np.meshgrid(x,x) # Obtiene coordenadas de una matriz\n",
    "sz=XX.shape\n",
    "data=np.c_[XX.ravel(),YY.ravel()] \n",
    "    # c_ transforma objetos individuales a concatenaciones en el segundo eje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predice la clase de los nuevos datos\n",
    "Z=clf.predict(data) # regresa las etiquetas de los datos\n",
    "print (Z) # Imprime las etiquetas de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las particiones espaciales\n",
    "plt.imshow(Z.reshape(sz), interpolation='bilinear', origin='lower', \n",
    "           extent=(-5,15,-5,15),alpha=0.3, vmin=0, vmax=K-1)\n",
    "plt.title('Particiones espaciales', size=14)\n",
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='b')\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='g')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cluster.KMeans(n_clusters=K, random_state=0) \n",
    "    # Inicializar la clasificación por k-means\n",
    "clf.fit(X) # ejecutar el método k-means\n",
    "\n",
    "data=np.c_[XX.ravel(),YY.ravel()] \n",
    "Z=clf.predict(data) # regresar las etiquetas de las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Resultado final de K-means', size=14)\n",
    "\n",
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='b')\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='g')\n",
    "\n",
    "plt.imshow(Z.reshape(sz), interpolation='bilinear', origin='lower', \n",
    "           extent=(-5,15,-5,15),alpha=0.3, vmin=0, vmax=K-1)\n",
    "\n",
    "x = np.linspace(-5,15,200)\n",
    "XX,YY = np.meshgrid(x,x)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cluster.KMeans(init='random', n_clusters=K, random_state=0) \n",
    "    # Inicializar la clasificación k-means\n",
    "clf.fit(X) # ejecutar la clasificación k-means\n",
    "Zx=clf.predict(X)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Etiquetas originales', size=14)\n",
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='b') # b\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='g')  # g\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((12,3))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Datos sin etiquetas', size=14)\n",
    "plt.scatter(X[(y==1).ravel(),0],X[(y==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(y==2).ravel(),0],X[(y==2).ravel(),1],color='r') # b\n",
    "plt.scatter(X[(y==3).ravel(),0],X[(y==3).ravel(),1],color='r')  # g\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((12,3))\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Etiquetas de clasificación', size=14)\n",
    "plt.scatter(X[(Zx==1).ravel(),0],X[(Zx==1).ravel(),1],color='r')\n",
    "plt.scatter(X[(Zx==2).ravel(),0],X[(Zx==2).ravel(),1],color='b')\n",
    "plt.scatter(X[(Zx==0).ravel(),0],X[(Zx==0).ravel(),1],color='g')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cluster.KMeans(n_clusters=K, init='k-means++',  random_state=0, max_iter=300, n_init=10) \n",
    "                                        # Inicializar la clasificación k-means\n",
    "clf.fit(X)                              # ejecutar la clasificación k-means\n",
    "\n",
    "print ('Evaluación final de la clasificación:')\n",
    "\n",
    "print('Inercia: %.2f' %  clf.inertia_)\n",
    "\n",
    "print('Índice aleatorio ajustado %.2f' % metrics.adjusted_rand_score(y.ravel(), clf.labels_))\n",
    "\n",
    "print('Homogeneidad %.2f' %  metrics.homogeneity_score(y.ravel(), clf.labels_))\n",
    "\n",
    "print('Completitud %.2f' %  metrics.completeness_score(y.ravel(), clf.labels_))\n",
    "             \n",
    "print('medida V %.2f' %  metrics.v_measure_score(y.ravel(), clf.labels_))\n",
    "\n",
    "print('Silueta %.2f' %  metrics.silhouette_score(X, clf.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = cluster.KMeans(n_clusters=K,  init='random', random_state=0, max_iter=2, n_init=2) \n",
    "                                    # Inicializar la clasificación k-means\n",
    "clf1.fit(X)                         # ejecutar la clasificación k-means\n",
    "\n",
    "print ('Evaluación final de la clasificación:')\n",
    "\n",
    "print ('Inercia: %.2f' % clf1.inertia_)\n",
    "\n",
    "print ('Índice aleatorio ajustado %.2f' % metrics.adjusted_rand_score(y.ravel(), clf1.labels_))\n",
    "\n",
    "print ('Homogeneidad %.2f' % metrics.homogeneity_score(y.ravel(),  clf1.labels_))\n",
    "\n",
    "print ('Completitud %.2f' % metrics.completeness_score(y.ravel(), clf1.labels_))\n",
    "             \n",
    "print ('medida V %.2f' % metrics.v_measure_score(y.ravel(), clf1.labels_))\n",
    "\n",
    "print ('Silueta %.2f' % metrics.silhouette_score(X, clf1.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Índice aleatorio ajustado %.2f' % metrics.adjusted_rand_score(y.ravel(), clf.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
